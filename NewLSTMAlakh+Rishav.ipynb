{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewLSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMc0Pgf3yBwSRlKNRvMV2+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atusharkm/hello-world/blob/master/NewLSTMAlakh%2BRishav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEiQJz3MH0Oi"
      },
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import *\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Fltj9DH7p5"
      },
      "source": [
        "df = pd.read_excel('Tata_consumer_returns_price_beta.xlsx')\n",
        "df = df.iloc[19:,: ]\n",
        "df = df.drop(['CloseNIFTY50', 'Dailyu Returns', 'Date.1'], axis=1)\n",
        "\n",
        "df.columns = ['Date', 'Close', 'Returns', 'Beta', 'Volatility']\n",
        "\n",
        "df['Date'] = pd.to_datetime(df.Date, format='%d-%m-%Y %H:%M')\n",
        "df['Date'] = pd.to_datetime(df.Date).dt.date\n",
        "df.index = df['Date']\n",
        "\n",
        "df = df.drop(['Date'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OvgCrpWH70h"
      },
      "source": [
        "values = df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgoxKlp-H73J"
      },
      "source": [
        "groups = [0, 1, 2, 3]\n",
        "i = 1\n",
        "# plot each column\n",
        "plt.figure()\n",
        "for group in groups:\n",
        "    plt.subplot(len(groups), 1, i)\n",
        "    plt.plot(values[:, group])\n",
        "    plt.title(df.columns[group], y=0.5, loc='right')\n",
        "    i += 1\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvJHbX_VH75W"
      },
      "source": [
        "df = df.replace('?', np.nan)\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h6DTNg1H778"
      },
      "source": [
        "train_size = int(len(df)*0.8)\n",
        "# Fitting the RNN to the Training settrain_size = int(len(df_scaled)*0.8)\n",
        "test_size = len(df) - train_size\n",
        "\n",
        "train_df,test_df = df[:train_size], df[train_size:len(df)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa5sQjYsH7-h"
      },
      "source": [
        "train = train_df\n",
        "scalers={}\n",
        "for i in train_df.columns:\n",
        "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "    s_s = scaler.fit_transform(train[i].values.reshape(-1,1))\n",
        "    s_s=np.reshape(s_s,len(s_s))\n",
        "    scalers['scaler_'+ i] = scaler\n",
        "    train[i]=s_s\n",
        "test = test_df\n",
        "for i in train_df.columns:\n",
        "    scaler = scalers['scaler_'+i]\n",
        "    s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
        "    s_s=np.reshape(s_s,len(s_s))\n",
        "    scalers['scaler_'+i] = scaler\n",
        "    test[i]=s_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJmMASXhH8A0"
      },
      "source": [
        "def split_series(series, n_past, n_future):\n",
        "  # n_past ==> no of past observations\n",
        "  # n_future ==> no of future observations\n",
        " \n",
        "  X, y = list(), list()\n",
        "  for window_start in range(len(series)):\n",
        "    past_end = window_start + n_past\n",
        "    future_end = past_end + n_future\n",
        "    if future_end > len(series):\n",
        "      break\n",
        "    # slicing the past and future parts of the window\n",
        "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
        "    X.append(past)\n",
        "    y.append(future)\n",
        "  return np.array(X), np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc0J01WPH8C_"
      },
      "source": [
        "n_past = 60\n",
        "n_future = 10\n",
        "n_features = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HgfVxDoIXlb"
      },
      "source": [
        "X_train, y_train = split_series(train.values,n_past, n_future)\n",
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
        "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
        "X_test, y_test = split_series(test.values,n_past, n_future)\n",
        "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
        "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nixWPQA4IXnx"
      },
      "source": [
        "# E2D2\n",
        "# n_features ==> no of features at each timestep in the data.\n",
        "#\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
        "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
        "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "encoder_states1 = encoder_outputs1[1:]\n",
        "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
        "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
        "encoder_states2 = encoder_outputs2[1:]\n",
        "#\n",
        "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
        "#\n",
        "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
        "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
        "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
        "#\n",
        "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
        "#\n",
        "model_e2d2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7CrsN64IXp_"
      },
      "source": [
        "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss='mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AtZzG5lIXr1"
      },
      "source": [
        "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),verbose=0,callbacks=[reduce_lr])\n",
        "\n",
        "pred_e2d2=model_e2d2.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfaUhGFKIXvD"
      },
      "source": [
        "for index,i in enumerate(train_df.columns):\n",
        "    scaler = scalers['scaler_'+i]\n",
        "    pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
        "    y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
        "    y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jAOQ007H8FJ"
      },
      "source": [
        "math.sqrt(mean_squared_error(y_test[:,0], pred_e2d2[:,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S76J9E0kH8Ib"
      },
      "source": [
        "plt.plot(y_test[:,0], color = 'red', label = 'Actual Stock Price')\n",
        "plt.plot(pred_e2d2[:,0], color = 'blue', label = 'Predicted Stock Price')\n",
        "plt.title('TATA CONSUMERS' )\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('TATACON Stock Price')\n",
        "plt.legend()\n",
        "plt.xticks(np.arange(0,459,60))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}